{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T13:58:59.460735Z",
     "iopub.status.busy": "2024-09-17T13:58:59.459718Z",
     "iopub.status.idle": "2024-09-17T13:59:00.323640Z",
     "shell.execute_reply": "2024-09-17T13:59:00.322660Z",
     "shell.execute_reply.started": "2024-09-17T13:58:59.460678Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io as sio\n",
    "directory = '/kaggle/input/eeg-datasettt-2/Dataset-2/Alzhimer/CONTROL'\n",
    "file_list = [file for file in os.listdir(directory) if file.endswith('.mat')]\n",
    "Normal = []\n",
    "for file in file_list:\n",
    "    file_path = os.path.join(directory, file)\n",
    "    mat_data = sio.loadmat(file_path)\n",
    "    Normal.append(mat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T13:59:00.325809Z",
     "iopub.status.busy": "2024-09-17T13:59:00.325382Z",
     "iopub.status.idle": "2024-09-17T13:59:00.333468Z",
     "shell.execute_reply": "2024-09-17T13:59:00.332494Z",
     "shell.execute_reply.started": "2024-09-17T13:59:00.325771Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "Normal_data = []\n",
    "for i in range(len(Normal)):\n",
    "    try:\n",
    "        data = Normal[i]['segmenty']\n",
    "        Normal_data.append(data)\n",
    "    except:\n",
    "        data = Normal[i]['export']\n",
    "        data = np.transpose(data)\n",
    "        Normal_data.append(data)\n",
    "        \n",
    "Normal_data = [lst[0:19] for lst in Normal_data]\n",
    "\n",
    "# for i in range(len(Normal_data)):\n",
    "#   print(np.array(Normal_data[i]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T13:59:00.335018Z",
     "iopub.status.busy": "2024-09-17T13:59:00.334726Z",
     "iopub.status.idle": "2024-09-17T13:59:00.733685Z",
     "shell.execute_reply": "2024-09-17T13:59:00.732895Z",
     "shell.execute_reply.started": "2024-09-17T13:59:00.334986Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path='/kaggle/input/eeg-datasettt-2/Dataset-2/Alzhimer/MCI'\n",
    "MCI = []\n",
    "for file in os.listdir(data_path):\n",
    "    file_path = os.path.join(data_path, file)\n",
    "    for i in os.listdir(file_path):\n",
    "        file_pa = os.path.join(file_path, i)\n",
    "        mat_data = sio.loadmat(file_pa)\n",
    "        MCI.append(mat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T13:59:00.735958Z",
     "iopub.status.busy": "2024-09-17T13:59:00.735649Z",
     "iopub.status.idle": "2024-09-17T13:59:00.741065Z",
     "shell.execute_reply": "2024-09-17T13:59:00.740199Z",
     "shell.execute_reply.started": "2024-09-17T13:59:00.735925Z"
    }
   },
   "outputs": [],
   "source": [
    "MCI_data = []\n",
    "for i in range(len(MCI)):\n",
    "    data = MCI[i]['export']\n",
    "    data = np.transpose(data)\n",
    "    MCI_data.append(data)\n",
    "\n",
    "# for i in range(len(MCI_data)):\n",
    "#     print(np.array(MCI_data[i]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T13:59:00.742688Z",
     "iopub.status.busy": "2024-09-17T13:59:00.742345Z",
     "iopub.status.idle": "2024-09-17T13:59:03.055251Z",
     "shell.execute_reply": "2024-09-17T13:59:03.054279Z",
     "shell.execute_reply.started": "2024-09-17T13:59:00.742655Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path='/kaggle/input/eeg-datasettt-2/Dataset-2/Alzhimer/AD'\n",
    "AD = []\n",
    "for file in os.listdir(data_path):\n",
    "    file_path = os.path.join(data_path, file)\n",
    "    for i in os.listdir(file_path):\n",
    "        file_pa = os.path.join(file_path, i)\n",
    "        mat_data = sio.loadmat(file_pa)\n",
    "        AD.append(mat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T13:59:03.056908Z",
     "iopub.status.busy": "2024-09-17T13:59:03.056516Z",
     "iopub.status.idle": "2024-09-17T13:59:03.063657Z",
     "shell.execute_reply": "2024-09-17T13:59:03.062707Z",
     "shell.execute_reply.started": "2024-09-17T13:59:03.056865Z"
    }
   },
   "outputs": [],
   "source": [
    "AD_data = []\n",
    "for i in range(len(AD)):\n",
    "    data = AD[i]['export']\n",
    "    data = np.transpose(data)\n",
    "    AD_data.append(data)\n",
    "\n",
    "desired_length = 19\n",
    "AD_data = [arr for arr in AD_data if len(arr) == desired_length]\n",
    "\n",
    "# for i in range(len(AD_data)):\n",
    "#     print(np.array(AD_data[i]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T13:59:03.065135Z",
     "iopub.status.busy": "2024-09-17T13:59:03.064797Z",
     "iopub.status.idle": "2024-09-17T13:59:03.078966Z",
     "shell.execute_reply": "2024-09-17T13:59:03.078194Z",
     "shell.execute_reply.started": "2024-09-17T13:59:03.065095Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "Data = []\n",
    "label = []\n",
    "for i in range(len(Normal_data)):\n",
    "  Data.append(Normal_data[i])\n",
    "  label.append(0)\n",
    "\n",
    "for j in range(len(MCI_data)):\n",
    "  Data.append(MCI_data[j])\n",
    "  label.append(1)\n",
    "\n",
    "for k in range(len(AD_data)):\n",
    "  Data.append(AD_data[k])\n",
    "  label.append(2)\n",
    "    \n",
    "print(len(Data))\n",
    "print(len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T13:59:03.080202Z",
     "iopub.status.busy": "2024-09-17T13:59:03.079928Z",
     "iopub.status.idle": "2024-09-17T13:59:03.713793Z",
     "shell.execute_reply": "2024-09-17T13:59:03.712989Z",
     "shell.execute_reply.started": "2024-09-17T13:59:03.080159Z"
    }
   },
   "outputs": [],
   "source": [
    "Ndata=[]\n",
    "for i in  range(len(Data)):\n",
    "    std=np.std(Data[i],axis=1)\n",
    "    mean=np.mean(Data[i],axis=1)\n",
    "    Data[i]=(Data[i].transpose()-mean.transpose()).transpose()\n",
    "    Data[i]=(Data[i].transpose()/std.transpose()).transpose()\n",
    "    Ndata.append(Data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T13:59:03.715246Z",
     "iopub.status.busy": "2024-09-17T13:59:03.714915Z",
     "iopub.status.idle": "2024-09-17T14:54:31.638112Z",
     "shell.execute_reply": "2024-09-17T14:54:31.637057Z",
     "shell.execute_reply.started": "2024-09-17T13:59:03.715212Z"
    }
   },
   "outputs": [],
   "source": [
    "winSize = 256*4\n",
    "stride = 256*1\n",
    "WData_ch1 = []\n",
    "Nlabel = []\n",
    "for j in range(len(Ndata)):\n",
    "    count = 0\n",
    "    for i in range(0,np.shape(Ndata[j])[1]-winSize,stride):\n",
    "        count+=1\n",
    "        Nlabel.append(label[j])\n",
    "        if len(np.shape(WData_ch1))>1:\n",
    "            WData_ch1=np.dstack((WData_ch1, Ndata[j][:,i:i+winSize]))\n",
    "        else:\n",
    "            WData_ch1=np.reshape(Ndata[j][:,i:i+winSize],(19,np.shape(Ndata[j][:,i:i+winSize])[1],1))\n",
    "#     print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T14:54:31.641934Z",
     "iopub.status.busy": "2024-09-17T14:54:31.641618Z",
     "iopub.status.idle": "2024-09-17T14:54:32.095652Z",
     "shell.execute_reply": "2024-09-17T14:54:32.094653Z",
     "shell.execute_reply.started": "2024-09-17T14:54:31.641900Z"
    }
   },
   "outputs": [],
   "source": [
    "np.array(WData_ch1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T14:54:32.097039Z",
     "iopub.status.busy": "2024-09-17T14:54:32.096733Z",
     "iopub.status.idle": "2024-09-17T14:54:32.559089Z",
     "shell.execute_reply": "2024-09-17T14:54:32.558192Z",
     "shell.execute_reply.started": "2024-09-17T14:54:32.097007Z"
    }
   },
   "outputs": [],
   "source": [
    "WdataCh1 = np.array(WData_ch1)\n",
    "labelCh1 = np.array(Nlabel)\n",
    "print(\"Shape of Data\", WdataCh1.shape)\n",
    "print(\"Shape of Label\", labelCh1.shape)\n",
    "WdataCh11 = np.transpose(WdataCh1, (2, 0, 1))\n",
    "WdataCh11.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T14:54:32.561296Z",
     "iopub.status.busy": "2024-09-17T14:54:32.560886Z",
     "iopub.status.idle": "2024-09-17T14:54:44.862218Z",
     "shell.execute_reply": "2024-09-17T14:54:44.861444Z",
     "shell.execute_reply.started": "2024-09-17T14:54:32.561252Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('/kaggle/working/A_Data.npy', WdataCh11)\n",
    "np.save('/kaggle/working/A_Label.npy',labelCh1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T14:54:44.863791Z",
     "iopub.status.busy": "2024-09-17T14:54:44.863418Z",
     "iopub.status.idle": "2024-09-17T14:54:45.277742Z",
     "shell.execute_reply": "2024-09-17T14:54:45.276800Z",
     "shell.execute_reply.started": "2024-09-17T14:54:44.863747Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "Data = np.load('/kaggle/working/A_Data.npy')\n",
    "Label = np.load('/kaggle/working/A_Label.npy')\n",
    "print(\"Shape of the Data: \", Data.shape)\n",
    "print(\"Shape of the Label: \",Label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T14:54:45.279895Z",
     "iopub.status.busy": "2024-09-17T14:54:45.279184Z",
     "iopub.status.idle": "2024-09-17T14:54:45.521643Z",
     "shell.execute_reply": "2024-09-17T14:54:45.520805Z",
     "shell.execute_reply.started": "2024-09-17T14:54:45.279847Z"
    }
   },
   "outputs": [],
   "source": [
    "nan_indices = np.isnan(Data)\n",
    "\n",
    "# Replace NaN values with a specific value, for example, 0\n",
    "Data[nan_indices]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T14:54:45.523294Z",
     "iopub.status.busy": "2024-09-17T14:54:45.522908Z",
     "iopub.status.idle": "2024-09-17T14:55:07.733484Z",
     "shell.execute_reply": "2024-09-17T14:55:07.732450Z",
     "shell.execute_reply.started": "2024-09-17T14:54:45.523252Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "num_classes = 3\n",
    "Y = to_categorical(Label, num_classes)\n",
    "x,y = shuffle(Data, Y, random_state = 2)\n",
    "X_train, X_test, y_train,y_test = train_test_split(x, y, test_size = 0.1, random_state = 2)\n",
    "print(\"Shape of X_train:\",X_train.shape)\n",
    "print(\"Shape of X_test:\",X_test.shape)\n",
    "print(\"Shape of y_train:\",y_train.shape)\n",
    "print(\"Shape of y_test:\",y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T14:55:07.735216Z",
     "iopub.status.busy": "2024-09-17T14:55:07.734622Z",
     "iopub.status.idle": "2024-09-17T14:59:34.919369Z",
     "shell.execute_reply": "2024-09-17T14:59:34.918352Z",
     "shell.execute_reply.started": "2024-09-17T14:55:07.735174Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "x = X_train.reshape(15340, -1)\n",
    "np.savetxt(\"/kaggle/working/X_train.csv\", x, delimiter = \",\")\n",
    "\n",
    "q =  np.argmax(y_train, axis =1).reshape(15340, -1)\n",
    "np.savetxt(\"/kaggle/working/y_train.csv\", q,  delimiter = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T14:59:34.921020Z",
     "iopub.status.busy": "2024-09-17T14:59:34.920634Z",
     "iopub.status.idle": "2024-09-17T15:02:56.059297Z",
     "shell.execute_reply": "2024-09-17T15:02:56.057118Z",
     "shell.execute_reply.started": "2024-09-17T14:59:34.920977Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/kaggle/working/X_train.csv', header = None, delimiter = \",\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T15:02:56.061027Z",
     "iopub.status.busy": "2024-09-17T15:02:56.060724Z",
     "iopub.status.idle": "2024-09-17T15:07:24.738350Z",
     "shell.execute_reply": "2024-09-17T15:07:24.737391Z",
     "shell.execute_reply.started": "2024-09-17T15:02:56.060996Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "X = np.array(df)\n",
    "X_embedded = TSNE(n_components=2).fit_transform(X)\n",
    "\n",
    "df1 = pd.read_csv('/kaggle/working/y_train.csv', header = None,  delimiter = \",\")\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T15:07:24.740039Z",
     "iopub.status.busy": "2024-09-17T15:07:24.739653Z",
     "iopub.status.idle": "2024-09-17T15:07:28.106531Z",
     "shell.execute_reply": "2024-09-17T15:07:28.105592Z",
     "shell.execute_reply.started": "2024-09-17T15:07:24.739995Z"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.scatter(X_embedded, x =0, y = 1, color=df1[0], width=600, height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T15:07:28.108405Z",
     "iopub.status.busy": "2024-09-17T15:07:28.107936Z",
     "iopub.status.idle": "2024-09-17T15:07:28.879365Z",
     "shell.execute_reply": "2024-09-17T15:07:28.878406Z",
     "shell.execute_reply.started": "2024-09-17T15:07:28.108363Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming X_embedded is a 2D array or DataFrame with shape (n_samples, 2)\n",
    "# and df1[0] is a list or array of colors with length n_samples\n",
    "\n",
    "# Extract x and y coordinates\n",
    "x = X_embedded[:, 0]\n",
    "y = X_embedded[:, 1]\n",
    "\n",
    "# Create the scatter plot\n",
    "fig, ax = plt.subplots(figsize=(6, 5))  # Set the figure size to match the width and height in Plotly\n",
    "scatter = ax.scatter(x, y, c=df1[0], cmap='viridis', alpha=0.7)  # Use a colormap and set transparency\n",
    "\n",
    "# Add a color bar\n",
    "cbar = plt.colorbar(scatter)\n",
    "cbar.set_label('Color Intensity')\n",
    "\n",
    "# Add axis labels and a title\n",
    "ax.set_xlabel('X Coordinate')\n",
    "ax.set_ylabel('Y Coordinate')\n",
    "ax.set_title('Scatter Plot with Color Mapping')\n",
    "\n",
    "# Improve the grid and axis appearance\n",
    "ax.grid(True, linestyle='--', alpha=0.5)\n",
    "ax.set_axisbelow(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T15:07:28.880701Z",
     "iopub.status.busy": "2024-09-17T15:07:28.880415Z",
     "iopub.status.idle": "2024-09-17T15:07:28.887675Z",
     "shell.execute_reply": "2024-09-17T15:07:28.886803Z",
     "shell.execute_reply.started": "2024-09-17T15:07:28.880670Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 19,1024, 1)\n",
    "X_test = X_test.reshape(-1, 19, 1024, 1)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T15:07:28.889663Z",
     "iopub.status.busy": "2024-09-17T15:07:28.889222Z",
     "iopub.status.idle": "2024-09-17T15:07:29.518132Z",
     "shell.execute_reply": "2024-09-17T15:07:29.517385Z",
     "shell.execute_reply.started": "2024-09-17T15:07:28.889621Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sys,os,cv2\n",
    "import tensorflow as tf\n",
    "from keras.layers import Conv2D, Add, MaxPooling2D, AveragePooling2D, Activation, Dense, PReLU, Layer, DepthwiseConv2D\n",
    "from keras.layers import Input, BatchNormalization, GlobalAveragePooling2D, Concatenate, Cropping2D, Multiply, Lambda, Flatten, Reshape\n",
    "from keras.activations import relu, softmax, sigmoid, tanh, leaky_relu\n",
    "from keras import initializers\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "import keras.backend as K\n",
    "import h5py\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\n",
    "from keras.models import load_model, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T15:07:29.519910Z",
     "iopub.status.busy": "2024-09-17T15:07:29.519501Z",
     "iopub.status.idle": "2024-09-17T15:07:29.525371Z",
     "shell.execute_reply": "2024-09-17T15:07:29.524407Z",
     "shell.execute_reply.started": "2024-09-17T15:07:29.519864Z"
    }
   },
   "outputs": [],
   "source": [
    "def channel_split(x):\n",
    "    split_0 = x[:, :, :, :x.shape[-1] // 2]\n",
    "    split_1 = x[:, :, :, x.shape[-1] // 2:]\n",
    "    return split_0, split_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T15:07:29.527189Z",
     "iopub.status.busy": "2024-09-17T15:07:29.526629Z",
     "iopub.status.idle": "2024-09-17T15:07:29.540325Z",
     "shell.execute_reply": "2024-09-17T15:07:29.539441Z",
     "shell.execute_reply.started": "2024-09-17T15:07:29.527126Z"
    }
   },
   "outputs": [],
   "source": [
    "def Channel_attention(a1):\n",
    "    split_0, split_1 = channel_split(a1)\n",
    "    Conv3 = Conv2D(filters=64, kernel_size=(1, 3), dilation_rate = 1, padding = 'same', activation='relu')(split_0)\n",
    "    Conv3 = BatchNormalization()(Conv3)\n",
    "    maxi  = Conv2DTranspose(64, (1, 2), strides=(1, 1), padding='same', activation='relu')(Conv3)\n",
    "    Conv5 = Conv2D(filters=64, kernel_size=(1, 3), dilation_rate = 1, padding = 'same', activation='relu')(maxi)\n",
    "    Conv5 = BatchNormalization()(Conv5)\n",
    "    m1    = Multiply()([Conv3, Conv5])\n",
    "    Conv4 = Conv2D(filters=64, kernel_size=(1, 3), dilation_rate = 1, padding = 'same', activation='relu')(split_1)\n",
    "    Conv4 = BatchNormalization()(Conv4)\n",
    "    avg1  = Conv2DTranspose(64, (1, 2), strides=(1, 1), padding='same', activation='relu')(Conv4)\n",
    "    Conv6 = Conv2D(filters=64, kernel_size=(1, 3), dilation_rate = 1, padding = 'same', activation='relu')(avg1)\n",
    "    Conv6 = BatchNormalization()(Conv6)\n",
    "    m2    = Multiply()([Conv6, Conv4])\n",
    "    g1    = GlobalAveragePooling2D()(m1)\n",
    "    g2    = GlobalAveragePooling2D()(m2)\n",
    "    act1  = Activation('sigmoid')(g1)\n",
    "    act2  = Activation('sigmoid')(g2)\n",
    "    m3    = Multiply()([m1, act1])\n",
    "    m4    = Multiply()([m2, act2])\n",
    "    a4    = Add()([m3, m4])\n",
    "    return a4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T15:07:29.542002Z",
     "iopub.status.busy": "2024-09-17T15:07:29.541634Z",
     "iopub.status.idle": "2024-09-17T15:07:29.564277Z",
     "shell.execute_reply": "2024-09-17T15:07:29.563367Z",
     "shell.execute_reply.started": "2024-09-17T15:07:29.541961Z"
    }
   },
   "outputs": [],
   "source": [
    "def Spatial_attention(a1):\n",
    "    split_0, split_1 = channel_split(a1)\n",
    "    Conv3 = Conv2D(filters=64, kernel_size=(1, 3), dilation_rate = 1, padding = 'same', activation='relu')(split_0)\n",
    "    Conv3 = BatchNormalization()(Conv3)\n",
    "    avg   = Conv2DTranspose(64, (1, 2), strides=(1, 1), padding='same', activation='relu')(Conv3)\n",
    "    Conv5 = Conv2D(filters=64, kernel_size=(1, 3), dilation_rate = 1, padding = 'same', activation='relu')(avg)\n",
    "    Conv5 = BatchNormalization()(Conv5)\n",
    "    m1    = Multiply()([Conv3, Conv5])\n",
    "    Conv4 = Conv2D(filters=64, kernel_size=(1, 3), dilation_rate = 1, padding = 'same', activation='relu')(split_1)\n",
    "    Conv4 = BatchNormalization()(Conv4)\n",
    "    avg1  = Conv2DTranspose(64, (1, 2), strides=(1, 1), padding='same', activation='relu')(Conv4)\n",
    "    Conv6 = Conv2D(filters=64, kernel_size=(1, 3), dilation_rate = 1, padding = 'same', activation='relu')(avg1)\n",
    "    Conv6 = BatchNormalization()(Conv6)\n",
    "    m2    = Multiply()([Conv6, Conv4])\n",
    "    a4    = Add()([m1, m2])\n",
    "    Conv7 = Conv2D(filters=64, kernel_size=(1, 3), dilation_rate = 1, padding = 'same', activation='relu')(a4)\n",
    "    Conv7 = BatchNormalization()(Conv7)\n",
    "    Conv8 = Conv2D(filters=64, kernel_size=(1, 3), dilation_rate = 1, padding = 'same', activation='relu')(Conv7)\n",
    "    Conv8 = BatchNormalization()(Conv8)\n",
    "    s1    = Activation('sigmoid')(Conv8)\n",
    "    return s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T15:07:29.566401Z",
     "iopub.status.busy": "2024-09-17T15:07:29.565393Z",
     "iopub.status.idle": "2024-09-17T15:07:29.583244Z",
     "shell.execute_reply": "2024-09-17T15:07:29.582517Z",
     "shell.execute_reply.started": "2024-09-17T15:07:29.566367Z"
    }
   },
   "outputs": [],
   "source": [
    "def ASF(in1, in2):\n",
    "    Conv1 = Conv2D(filters=64, kernel_size=(1, 3), dilation_rate = 1, padding = 'same', activation='relu')(in1)\n",
    "    Conv1 = BatchNormalization()(Conv1)\n",
    "    Conv2 = Conv2D(filters=64, kernel_size=(1, 3), dilation_rate = 1, padding = 'same', activation='relu')(in2)\n",
    "    Conv2 = BatchNormalization()(Conv2)\n",
    "    a1    = Add()([Conv1, Conv2])\n",
    "    a4    = Channel_attention(a1)\n",
    "    a5    = Spatial_attention(a1)\n",
    "    a6    = Add()([a4, a5])\n",
    "    a7    = Activation('sigmoid')(a6)\n",
    "    a8    = Multiply()([a7, Conv1])\n",
    "    a9    = Multiply()([a7, Conv2])\n",
    "    a10   = Add()([a8, a9])\n",
    "    return a10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T15:07:29.584740Z",
     "iopub.status.busy": "2024-09-17T15:07:29.584460Z",
     "iopub.status.idle": "2024-09-17T15:07:29.595020Z",
     "shell.execute_reply": "2024-09-17T15:07:29.594183Z",
     "shell.execute_reply.started": "2024-09-17T15:07:29.584710Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def Cosin_similarity(input):\n",
    "    dot1 = tf.reduce_sum(input[0] * input[1], axis=1)\n",
    "    dot2 = tf.reduce_sum(input[0] * input[0], axis=1)\n",
    "    dot3 = tf.reduce_sum(input[1] * input[1], axis=1)\n",
    "    max_val = tf.maximum(tf.sqrt(dot2 * dot3), tf.keras.backend.epsilon())\n",
    "    value = dot1 / max_val\n",
    "    return tf.tanh(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T15:07:29.600417Z",
     "iopub.status.busy": "2024-09-17T15:07:29.600090Z",
     "iopub.status.idle": "2024-09-17T15:07:29.610525Z",
     "shell.execute_reply": "2024-09-17T15:07:29.609823Z",
     "shell.execute_reply.started": "2024-09-17T15:07:29.600386Z"
    }
   },
   "outputs": [],
   "source": [
    "def Bund(input):\n",
    "    alpha_1 = input[0]\n",
    "    alpha_2 = input[1]\n",
    "\n",
    "    alpha_l = alpha_1/(alpha_1+alpha_2)\n",
    "    alpha_g = alpha_2/(alpha_1+alpha_2)\n",
    "\n",
    "    return alpha_l, alpha_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T15:07:29.612432Z",
     "iopub.status.busy": "2024-09-17T15:07:29.611871Z",
     "iopub.status.idle": "2024-09-17T15:07:31.696400Z",
     "shell.execute_reply": "2024-09-17T15:07:31.695397Z",
     "shell.execute_reply.started": "2024-09-17T15:07:29.612389Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam, Nadam,Adamax,Adadelta\n",
    "from keras.layers import Input, Conv2D, LSTM, Add, Multiply, Concatenate, MaxPooling2D, AveragePooling2D, Flatten, Lambda\n",
    "from keras.layers import SeparableConv2D, MaxPooling2D, Flatten, Dense, GlobalAveragePooling2D, GlobalMaxPooling2D, BatchNormalization, Conv2DTranspose\n",
    "eps = 1.1e-5\n",
    "input1 = Input((19, 1024, 1))\n",
    "\n",
    "x = Conv2D(32, (1, 3), padding = 'same', dilation_rate = 1, activation='relu') (input1)\n",
    "xx = BatchNormalization(axis=-1, epsilon=eps)(x)\n",
    "\n",
    "x1 = Conv2D(32, (1, 3), padding = 'same', dilation_rate = 1, activation='relu')(x)\n",
    "x1 = BatchNormalization(axis=-1, epsilon=eps)(x1)\n",
    "\n",
    "x2 = Conv2D(32, (1, 3), padding = 'same',dilation_rate = 2, activation='relu')(x)\n",
    "x2 = BatchNormalization(axis=-1, epsilon=eps)(x2)\n",
    "\n",
    "x3 = Conv2D(32, (1, 3), padding = 'same', dilation_rate = 3, activation='relu')(x)\n",
    "x3 = BatchNormalization(axis=-1, epsilon=eps)(x3)\n",
    "\n",
    "x4 = Conv2D(32, (1, 3), padding = 'same', dilation_rate = 4, activation='relu')(x)\n",
    "x4 = BatchNormalization(axis=-1, epsilon=eps)(x4)\n",
    "\n",
    "\n",
    "x11 = Conv2D(32, (1, 3), padding = 'same', dilation_rate = 1, activation='relu')(x1)\n",
    "x11 = BatchNormalization(axis=-1, epsilon=eps)(x11)\n",
    "\n",
    "x21 = Conv2D(32, (1, 3), padding = 'same', dilation_rate = 2, activation='relu')(x2)\n",
    "x21 = BatchNormalization(axis=-1, epsilon=eps)(x21)\n",
    "\n",
    "x31 = Conv2D(32, (1, 3), padding = 'same', dilation_rate = 3, activation='relu')(x3)\n",
    "x31 = BatchNormalization(axis=-1, epsilon=eps)(x31)\n",
    "\n",
    "x41 = Conv2D(32, (1, 3), padding = 'same', dilation_rate = 4, activation='relu')(x4)\n",
    "x41 = BatchNormalization(axis=-1, epsilon=eps)(x41)\n",
    "\n",
    "a1 = Add()([x1, x11])\n",
    "a1 = Add()([a1, x])\n",
    "a2 = Add()([x2, x21])\n",
    "a2 = Add()([a2, x])\n",
    "a3 = Add()([x3, x31])\n",
    "a3 = Add()([a3, x])\n",
    "a4 = Add()([x4, x41])\n",
    "a4 = Add()([a4, x])\n",
    "\n",
    "Att1   = ASF(a1, a2)\n",
    "Att2   = ASF(a3, a4)\n",
    "\n",
    "x_l = Att1\n",
    "x_g = Att2\n",
    "\n",
    "x_lg = Multiply()([x_l, x_g])\n",
    "x_gl = Add()([x_l, x_g])\n",
    "x_c = Concatenate()([x_l, x_g])\n",
    "\n",
    "x_l = GlobalAveragePooling2D()(x_l)\n",
    "x_g = GlobalAveragePooling2D()(x_g)\n",
    "x_c = GlobalAveragePooling2D()(x_c)\n",
    "\n",
    "x_l = Dense(units=128, activation='relu')(x_l)\n",
    "x_g = Dense(units=128, activation='relu')(x_g)\n",
    "\n",
    "share_1 = Dense(units=512, activation='relu')\n",
    "share_2 = Dense(units=512, activation='relu')\n",
    "\n",
    "x_l = share_1(x_l)\n",
    "x_g = share_1(x_g)\n",
    "x_c = share_1(x_c)\n",
    "\n",
    "x_l = share_2(x_l)\n",
    "x_g = share_2(x_g)\n",
    "x_c = share_2(x_c)\n",
    "\n",
    "alpha_1 = Lambda(Cosin_similarity, output_shape= (None, 1))([x_l, x_c])\n",
    "alpha_2 = Lambda(Cosin_similarity, output_shape= (None, 1))([x_g, x_c])\n",
    "alpha_l, alpha_g = Lambda(Bund)([alpha_1, alpha_2])\n",
    "out_l = Multiply()([alpha_l, x_l])\n",
    "out_g = Multiply()([alpha_g, x_g])\n",
    "\n",
    "out = Concatenate()([out_l, out_g])\n",
    "# out = Dense(units=512, activation=\"relu\")(out)\n",
    "out = Dense(units=256, activation=\"relu\")(out)\n",
    "\n",
    "out = Dense(units=3, activation=\"softmax\")(out)\n",
    "model = Model(inputs=input1, outputs=out)\n",
    "opt = Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(optimizer= opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T15:07:31.697999Z",
     "iopub.status.busy": "2024-09-17T15:07:31.697680Z",
     "iopub.status.idle": "2024-09-17T15:07:31.900938Z",
     "shell.execute_reply": "2024-09-17T15:07:31.900021Z",
     "shell.execute_reply.started": "2024-09-17T15:07:31.697966Z"
    }
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T15:07:31.902474Z",
     "iopub.status.busy": "2024-09-17T15:07:31.902085Z",
     "iopub.status.idle": "2024-09-17T15:07:31.908901Z",
     "shell.execute_reply": "2024-09-17T15:07:31.907980Z",
     "shell.execute_reply.started": "2024-09-17T15:07:31.902431Z"
    }
   },
   "outputs": [],
   "source": [
    "input1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T15:07:31.910453Z",
     "iopub.status.busy": "2024-09-17T15:07:31.910164Z",
     "iopub.status.idle": "2024-09-17T17:27:51.776160Z",
     "shell.execute_reply": "2024-09-17T17:27:51.775108Z",
     "shell.execute_reply.started": "2024-09-17T15:07:31.910415Z"
    }
   },
   "outputs": [],
   "source": [
    "# model.compile(optimizer= Adam(learning_rate=0.0001, weight_decay = 1e-6), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "early_stopping = EarlyStopping(\n",
    "                              patience=50,\n",
    "                              min_delta=0.001,\n",
    "                              monitor=\"val_accuracy\",\n",
    "                              restore_best_weights=True\n",
    "                              )\n",
    "# Define the model checkpoint callback to save the best weights\n",
    "checkpoint = ModelCheckpoint('/kaggle/working/'+'-{epoch:02d}.keras', monitor='val_accuracy', save_best_only=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size= 16, epochs= 20,\n",
    "                    verbose=1, validation_data=(X_test, y_test), callbacks=[early_stopping, checkpoint], shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T17:27:51.778099Z",
     "iopub.status.busy": "2024-09-17T17:27:51.777781Z",
     "iopub.status.idle": "2024-09-17T17:27:51.792352Z",
     "shell.execute_reply": "2024-09-17T17:27:51.791460Z",
     "shell.execute_reply.started": "2024-09-17T17:27:51.778065Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_model_complexity(model):\n",
    "    trainable_params = np.sum([np.prod(v.shape) for v in model.trainable_weights])\n",
    "    non_trainable_params = np.sum([np.prod(v.shape) for v in model.non_trainable_weights])\n",
    "    total_params = trainable_params + non_trainable_params\n",
    "\n",
    "    # Display parameters in both original and millions\n",
    "    print(f\"Trainable params: {trainable_params:,} ({trainable_params / 1e6:.2f} M)\")\n",
    "    print(f\"Non-trainable params: {non_trainable_params:,} ({non_trainable_params / 1e6:.2f} M)\")\n",
    "    print(f\"Total params: {total_params:,} ({total_params / 1e6:.2f} M)\")\n",
    "\n",
    "    # Rough estimate of FLOPs\n",
    "    flops = 2 * total_params  # This is a very rough estimate\n",
    "    print(f\"Estimated FLOPs: {flops:,} ({flops / 1e6:.2f} M)\")\n",
    "\n",
    "    # Estimate of MACs\n",
    "    macs = total_params  # For fully connected layers, MACs are equal to params\n",
    "    print(f\"Estimated MACs: {macs:,} ({macs / 1e6:.2f} M)\")\n",
    "\n",
    "    return {\n",
    "        \"Trainable params\": trainable_params,\n",
    "        \"Non-trainable params\": non_trainable_params,\n",
    "        \"Total params\": total_params,\n",
    "        \"Estimated FLOPs\": flops,\n",
    "        \"Estimated MACs\": macs\n",
    "    }\n",
    "\n",
    "# Assuming 'model' is your defined and compiled model\n",
    "try:\n",
    "    complexity = get_model_complexity(model)\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "    print(\"Please ensure your model is correctly defined and compiled.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T17:27:51.793879Z",
     "iopub.status.busy": "2024-09-17T17:27:51.793580Z",
     "iopub.status.idle": "2024-09-17T17:28:22.008492Z",
     "shell.execute_reply": "2024-09-17T17:28:22.007485Z",
     "shell.execute_reply.started": "2024-09-17T17:27:51.793848Z"
    }
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# Predicting the Test set results\n",
    "pred = model.predict(X_test)\n",
    "print(\"Y_pred:\", pred)\n",
    "print(\"*****************\")\n",
    "y_pred = np.argmax(pred, axis = 1)\n",
    "y_true = np.argmax(y_test, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T17:49:03.401643Z",
     "iopub.status.busy": "2024-09-17T17:49:03.400769Z",
     "iopub.status.idle": "2024-09-17T17:49:04.359705Z",
     "shell.execute_reply": "2024-09-17T17:49:04.358748Z",
     "shell.execute_reply.started": "2024-09-17T17:49:03.401600Z"
    }
   },
   "outputs": [],
   "source": [
    "#Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "target_names = ['Normal', 'MCI','AD']\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "p = sns.heatmap(pd.DataFrame(cm), annot=True,xticklabels=target_names, yticklabels=target_names, cmap=\"YlGnBu\" ,fmt='g')\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.savefig('/kaggle/working/D1_Task_CM.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T17:49:05.309484Z",
     "iopub.status.busy": "2024-09-17T17:49:05.307975Z",
     "iopub.status.idle": "2024-09-17T17:49:05.808257Z",
     "shell.execute_reply": "2024-09-17T17:49:05.807267Z",
     "shell.execute_reply.started": "2024-09-17T17:49:05.309434Z"
    }
   },
   "outputs": [],
   "source": [
    "#Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "target_names = ['Normal', 'MCI','AD']\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "cm = cm.astype('float')/cm.sum(axis=1)[:, np.newaxis]\n",
    "p = sns.heatmap(pd.DataFrame(cm), annot=True,xticklabels=target_names, yticklabels=target_names, cmap=\"YlGnBu\" ,fmt='.2f')\n",
    "plt.title('Confusion matrix', y=1.1)\n",
    "plt.ylabel('Actual label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.savefig('/kaggle/working/D1_Task_NCM.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T17:49:06.497505Z",
     "iopub.status.busy": "2024-09-17T17:49:06.497106Z",
     "iopub.status.idle": "2024-09-17T17:49:06.512517Z",
     "shell.execute_reply": "2024-09-17T17:49:06.511379Z",
     "shell.execute_reply.started": "2024-09-17T17:49:06.497461Z"
    }
   },
   "outputs": [],
   "source": [
    "#import classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_true,y_pred, target_names = target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T17:49:07.320566Z",
     "iopub.status.busy": "2024-09-17T17:49:07.319702Z",
     "iopub.status.idle": "2024-09-17T17:49:07.642078Z",
     "shell.execute_reply": "2024-09-17T17:49:07.641190Z",
     "shell.execute_reply.started": "2024-09-17T17:49:07.320524Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "from itertools import cycle\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "lw=2\n",
    "for i in range(3):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "colors =cycle(['blue', 'green', 'red','darkorange'])\n",
    "for i, color in zip(range(3), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label='AUC of {0} = {1:0.4f}'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate',fontsize=15)\n",
    "plt.ylabel('True Positive Rate',fontsize=15)\n",
    "# plt.title('Receiver operating characteristic for multi-class data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.savefig('/kaggle/working/A_ROC.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T17:49:08.282032Z",
     "iopub.status.busy": "2024-09-17T17:49:08.281357Z",
     "iopub.status.idle": "2024-09-17T17:49:08.288352Z",
     "shell.execute_reply": "2024-09-17T17:49:08.287382Z",
     "shell.execute_reply.started": "2024-09-17T17:49:08.281993Z"
    }
   },
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    print(layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T17:49:08.953093Z",
     "iopub.status.busy": "2024-09-17T17:49:08.952250Z",
     "iopub.status.idle": "2024-09-17T17:52:09.104568Z",
     "shell.execute_reply": "2024-09-17T17:52:09.103572Z",
     "shell.execute_reply.started": "2024-09-17T17:49:08.953044Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "model = model\n",
    "layer_name = 'dense_4'  # Put the 2nd last layer of the above output\n",
    "intermediate_layer_model = Model(inputs = model.input, outputs = model.get_layer(layer_name).output)\n",
    "intermediate_output1 = intermediate_layer_model.predict([X_train])\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "np.savetxt(\"/kaggle/working/A_X_train_Proposed_Feature.csv\", intermediate_output1, delimiter = \",\")\n",
    "\n",
    "df2 = pd.read_csv(\"/kaggle/working/A_X_train_Proposed_Feature.csv\", header = None, delimiter = \",\")\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "X1 = np.array(df2)\n",
    "X_embedded1 = TSNE(n_components=2).fit_transform(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-17T17:52:09.107025Z",
     "iopub.status.busy": "2024-09-17T17:52:09.106374Z",
     "iopub.status.idle": "2024-09-17T17:52:09.182658Z",
     "shell.execute_reply": "2024-09-17T17:52:09.181803Z",
     "shell.execute_reply.started": "2024-09-17T17:52:09.106984Z"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.scatter(X_embedded1, x =0, y = 1, color=df1[0], width=600, height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**END, THANK YOU!**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5720407,
     "sourceId": 9418610,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30762,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
